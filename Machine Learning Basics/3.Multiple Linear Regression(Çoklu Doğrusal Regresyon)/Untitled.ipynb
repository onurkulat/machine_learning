{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Çoklu Doğrusal Regresyon(Multiple Linear Regression)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bir tane bağımlı değişken ile bununla ilişkisi olan bir dizi bağımsız değişken arasındaki ilişkiyi ortaya koymak için yapılan analizdir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basit Doğrusal Regresyon Örneği "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(e --> error rate)\n",
    "y = a + bx\n",
    "\n",
    "y1=a+bx1+e1\n",
    "\n",
    "Satış = a + b(Ay) + e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Çoklu Doğrusal Regresyon Örneği"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y = b0 + b1x1 + b2x2 + b3x3 + e\n",
    "Boy = a + b(kilo) + c(yaş) + d(ayakkabı no) + e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kukla Değişken (Dummy Variable) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Birden fazla karakter veya durum tek kukla değişken ile gösterilmeyip her bir karakter bir kukla değişken ile ifade edilirse çoklu doğrusal bağlılık problemi ortaya çıkar ve parametreler tahmin edilemez. Bu durum kukla değişken tuzağı olarak adlandırılır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olasılık Değeri(P-Value) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-H0:null hypothesis:Farksızlık hipotezi, sıfır hipotezi,boş hipotez\n",
    "-H1:Alternatif hipotez\n",
    "-P-değeri:Olasılık değeri(genelde 0.05 alınır)\n",
    "-P-değeri küçüldükçe H0 hatalı olma ihtimali artar.\n",
    "-P-değeri büyüdükçe H1 hatalı olma ihtimali artar."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-H0 örneği:Derslere çalıştıkça dersteki başarı artar.\n",
    "-H1 örneği:H0'ın ters durumudur, Derslere çalıştıkça başarı artmaz veya artmaya bilir.\n",
    "P-değeri ne kadar örnek bulursam, bu hipotezi çürütebilirim(h0 hipotezi için)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Çok Değişkenli Modellerde, Değişken Seçimi "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*Bütün değişkenleri dahil etmek\n",
    "*Skor karşılaştırması(Score Comparison)\n",
    "\n",
    "*Geriye doğru eleme(Backward Elimination)\n",
    "*İleri seçim(Forward Selection)                     -->Adım adım karşılaştırma\n",
    "*İki yönlü eleme(Bidirectional elimination)                  Stepwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bütün Değişkenler"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bütün değişkenleri dahil ediyoruz,herhangi birisini eleme gibi bir durum yok"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*Şayet değişken seçimi(selection) yapıldıysa ve değişkenlerden eminse\n",
    "*Zorunluluk varsa\n",
    "*diğer 4 yöntemi kullanmadan önce bir ön fikir elde etmek için"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geriye Doğru Eleme(Backward Elimination) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Önce bütün değişkenleri dahil ederiz ve sistemde bir başarı ölçeriz, sonrada teker teker eleyerek ilerleriz."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Significance Level(SL) seçilir. (geneled 0.05)\n",
    "2.Bütün değişkenler kullanılarak bir model inşa edilir.\n",
    "3.En yüksek p-value değerine sahip olan bir değişken ele alınır ve şayet P>SL ise 4.adıma, değilse son adıma(6.adıma) gidilir\n",
    "4.Bu aşamada,3.adımda seçilen ve en yüksek p-değerine sahpi değişken sistemden kaldırılır.\n",
    "5.Makine öğrenmesi güncellenir ve 3.adıma geri dönülür.\n",
    "6.Makine öğrenmesi sonlandırılır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### İleriye Seçim(Forward Selection) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Significance Level(SL) seçilir. (geneled 0.05)\n",
    "2.Bütün değişkenler kullanılarak bir model inşa edilir.\n",
    "3.En düşük p-value değerine sahip olan değişken ele alınır.\n",
    "4.Bu aşamada, 3.adımda seçilen değişken sabit tutularak yeni bir değişken daha seçilir ve sisteme eklenir\n",
    "5.Makine öğrenmesi güncellenir ve 3.adıma geri dönülür, şayet en düşük p-değere sahip değişken için p<SL şartı sağlanıyorsa 3.Adıma dönülür,Sağlanmıyorsa biter.\n",
    "6.Makine öğrenmesi sonlandırılır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Çift Yönlü Eleme(Bidirecitonal Elimination)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Significance Level (SL) seçilir (genelde 0.05)\n",
    "2.Bütün değişkenler kullanılarak model inşa edilir.\n",
    "3.En düşük p-value değerine sahip olan değişken ele alınır.\n",
    "4.Bu aşamada, 3.adımda seçilen değişken sabit tutularak diğer bütün değişkenler sisteme dahil edilir ve en düşük p değerine sahip olan sistem de kalır.\n",
    "5.SL değerinin altında olan değişkenler sistemde kalır ve eski değişkenlerden hiçbirisi sistemden çıkarılamaz.\n",
    "6.Makine öğrenmesi sonlanır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bütün Yöntemler "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Başarı kriteri belirlenir.\n",
    "2.Bütün olası regresyon modelleri inşa edilir(ikili seçim olur)\n",
    "3.Başta belirlenen kriteri(1.adım) en iyi sağlayan yöntem seçilir.\n",
    "4.Makine öğrenmesi sonlandırılır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Çoklu Değişken İçin Veri Hazırlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['tr']\n",
      " ['us']\n",
      " ['us']\n",
      " ['us']\n",
      " ['us']\n",
      " ['us']\n",
      " ['us']\n",
      " ['fr']\n",
      " ['fr']\n",
      " ['fr']\n",
      " ['fr']\n",
      " ['fr']\n",
      " ['fr']\n",
      " ['fr']]\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "[['e']\n",
      " ['e']\n",
      " ['k']\n",
      " ['k']\n",
      " ['e']\n",
      " ['e']\n",
      " ['e']\n",
      " ['e']\n",
      " ['k']\n",
      " ['e']\n",
      " ['k']\n",
      " ['k']\n",
      " ['k']\n",
      " ['k']\n",
      " ['k']\n",
      " ['e']\n",
      " ['e']\n",
      " ['e']\n",
      " ['e']\n",
      " ['k']\n",
      " ['k']\n",
      " ['k']]\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "     fr   tr   us\n",
      "0   0.0  1.0  0.0\n",
      "1   0.0  1.0  0.0\n",
      "2   0.0  1.0  0.0\n",
      "3   0.0  1.0  0.0\n",
      "4   0.0  1.0  0.0\n",
      "5   0.0  1.0  0.0\n",
      "6   0.0  1.0  0.0\n",
      "7   0.0  1.0  0.0\n",
      "8   0.0  1.0  0.0\n",
      "9   0.0  0.0  1.0\n",
      "10  0.0  0.0  1.0\n",
      "11  0.0  0.0  1.0\n",
      "12  0.0  0.0  1.0\n",
      "13  0.0  0.0  1.0\n",
      "14  0.0  0.0  1.0\n",
      "15  1.0  0.0  0.0\n",
      "16  1.0  0.0  0.0\n",
      "17  1.0  0.0  0.0\n",
      "18  1.0  0.0  0.0\n",
      "19  1.0  0.0  0.0\n",
      "20  1.0  0.0  0.0\n",
      "21  1.0  0.0  0.0\n",
      "    boy  kilo  yas\n",
      "0   130    30   10\n",
      "1   125    36   11\n",
      "2   135    34   10\n",
      "3   133    30    9\n",
      "4   129    38   12\n",
      "5   180    90   30\n",
      "6   190    80   25\n",
      "7   175    90   35\n",
      "8   177    60   22\n",
      "9   185   105   33\n",
      "10  165    55   27\n",
      "11  155    50   44\n",
      "12  160    58   39\n",
      "13  162    59   41\n",
      "14  167    62   55\n",
      "15  174    70   47\n",
      "16  193    90   23\n",
      "17  187    80   27\n",
      "18  183    88   28\n",
      "19  159    40   29\n",
      "20  164    66   32\n",
      "21  166    56   42\n",
      "['e' 'e' 'k' 'k' 'e' 'e' 'e' 'e' 'k' 'e' 'k' 'k' 'k' 'k' 'k' 'e' 'e' 'e'\n",
      " 'e' 'k' 'k' 'k']\n",
      "    cinsiyet\n",
      "0        1.0\n",
      "1        1.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        1.0\n",
      "5        1.0\n",
      "6        1.0\n",
      "7        1.0\n",
      "8        0.0\n",
      "9        1.0\n",
      "10       0.0\n",
      "11       0.0\n",
      "12       0.0\n",
      "13       0.0\n",
      "14       0.0\n",
      "15       1.0\n",
      "16       1.0\n",
      "17       1.0\n",
      "18       1.0\n",
      "19       0.0\n",
      "20       0.0\n",
      "21       0.0\n",
      "     fr   tr   us  boy  kilo  yas\n",
      "0   0.0  1.0  0.0  130    30   10\n",
      "1   0.0  1.0  0.0  125    36   11\n",
      "2   0.0  1.0  0.0  135    34   10\n",
      "3   0.0  1.0  0.0  133    30    9\n",
      "4   0.0  1.0  0.0  129    38   12\n",
      "5   0.0  1.0  0.0  180    90   30\n",
      "6   0.0  1.0  0.0  190    80   25\n",
      "7   0.0  1.0  0.0  175    90   35\n",
      "8   0.0  1.0  0.0  177    60   22\n",
      "9   0.0  0.0  1.0  185   105   33\n",
      "10  0.0  0.0  1.0  165    55   27\n",
      "11  0.0  0.0  1.0  155    50   44\n",
      "12  0.0  0.0  1.0  160    58   39\n",
      "13  0.0  0.0  1.0  162    59   41\n",
      "14  0.0  0.0  1.0  167    62   55\n",
      "15  1.0  0.0  0.0  174    70   47\n",
      "16  1.0  0.0  0.0  193    90   23\n",
      "17  1.0  0.0  0.0  187    80   27\n",
      "18  1.0  0.0  0.0  183    88   28\n",
      "19  1.0  0.0  0.0  159    40   29\n",
      "20  1.0  0.0  0.0  164    66   32\n",
      "21  1.0  0.0  0.0  166    56   42\n",
      "     fr   tr   us  boy  kilo  yas  cinsiyet\n",
      "0   0.0  1.0  0.0  130    30   10       1.0\n",
      "1   0.0  1.0  0.0  125    36   11       1.0\n",
      "2   0.0  1.0  0.0  135    34   10       0.0\n",
      "3   0.0  1.0  0.0  133    30    9       0.0\n",
      "4   0.0  1.0  0.0  129    38   12       1.0\n",
      "5   0.0  1.0  0.0  180    90   30       1.0\n",
      "6   0.0  1.0  0.0  190    80   25       1.0\n",
      "7   0.0  1.0  0.0  175    90   35       1.0\n",
      "8   0.0  1.0  0.0  177    60   22       0.0\n",
      "9   0.0  0.0  1.0  185   105   33       1.0\n",
      "10  0.0  0.0  1.0  165    55   27       0.0\n",
      "11  0.0  0.0  1.0  155    50   44       0.0\n",
      "12  0.0  0.0  1.0  160    58   39       0.0\n",
      "13  0.0  0.0  1.0  162    59   41       0.0\n",
      "14  0.0  0.0  1.0  167    62   55       0.0\n",
      "15  1.0  0.0  0.0  174    70   47       1.0\n",
      "16  1.0  0.0  0.0  193    90   23       1.0\n",
      "17  1.0  0.0  0.0  187    80   27       1.0\n",
      "18  1.0  0.0  0.0  183    88   28       1.0\n",
      "19  1.0  0.0  0.0  159    40   29       0.0\n",
      "20  1.0  0.0  0.0  164    66   32       0.0\n",
      "21  1.0  0.0  0.0  166    56   42       0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. kutuphaneler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#2. Veri Onisleme\n",
    "\n",
    "#2.1. Veri Yukleme\n",
    "veriler = pd.read_csv('veriler.csv')\n",
    "#pd.read_csv(\"veriler.csv\")\n",
    "\n",
    "\n",
    "#veri on isleme\n",
    "\n",
    "\n",
    "Yas = veriler.iloc[:,1:4].values\n",
    "\n",
    "\n",
    "#encoder:  Kategorik -> Numeric\n",
    "ulke = veriler.iloc[:,0:1].values\n",
    "print(ulke)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "ulke[:,0] = le.fit_transform(ulke[:,0])\n",
    "print(ulke)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(categories=\"auto\")\n",
    "ulke=ohe.fit_transform(ulke).toarray()\n",
    "print(ulke)\n",
    "\n",
    "c = veriler.iloc[:,-1:].values\n",
    "print(c)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "c[:,0] = le.fit_transform(c[:,0])\n",
    "print(c)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(categories=\"auto\")\n",
    "c=ohe.fit_transform(c).toarray()\n",
    "print(c)\n",
    "\n",
    "\n",
    "\n",
    "#numpy dizileri dataframe donusumu\n",
    "sonuc = pd.DataFrame(data = ulke, index = range(22), columns=['fr','tr','us'] )\n",
    "print(sonuc)\n",
    "\n",
    "sonuc2 =pd.DataFrame(data = Yas, index = range(22), columns = ['boy','kilo','yas'])\n",
    "print(sonuc2)\n",
    "\n",
    "cinsiyet = veriler.iloc[:,-1].values\n",
    "print(cinsiyet)\n",
    "\n",
    "sonuc3 = pd.DataFrame(data = c[:,:1] , index=range(22), columns=['cinsiyet'])\n",
    "print(sonuc3)\n",
    "\n",
    "#dataframe birlestirme islemi\n",
    "s=pd.concat([sonuc,sonuc2],axis=1)\n",
    "print(s)\n",
    "\n",
    "s2= pd.concat([s,sonuc3],axis=1)\n",
    "print(s2)\n",
    "\n",
    "#verilerin egitim ve test icin bolunmesi\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train,y_test = train_test_split(s,sonuc3,test_size=0.33, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. kutuphaneler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#2. Veri Onisleme\n",
    "\n",
    "#2.1. Veri Yukleme\n",
    "veriler = pd.read_csv('veriler.csv')\n",
    "#pd.read_csv(\"veriler.csv\")\n",
    "\n",
    "\n",
    "#veri on isleme\n",
    "\n",
    "\n",
    "Yas = veriler.iloc[:,1:4].values\n",
    "\n",
    "\n",
    "#encoder:  Kategorik -> Numeric\n",
    "ulke = veriler.iloc[:,0:1].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "ulke[:,0] = le.fit_transform(ulke[:,0])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(categories=\"auto\")\n",
    "ulke=ohe.fit_transform(ulke).toarray()\n",
    "\n",
    "\n",
    "c = veriler.iloc[:,-1:].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "c[:,0] = le.fit_transform(c[:,0])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(categories=\"auto\")\n",
    "c=ohe.fit_transform(c).toarray()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#numpy dizileri dataframe donusumu\n",
    "sonuc = pd.DataFrame(data = ulke, index = range(22), columns=['fr','tr','us'] )\n",
    "\n",
    "\n",
    "sonuc2 =pd.DataFrame(data = Yas, index = range(22), columns = ['boy','kilo','yas'])\n",
    "\n",
    "\n",
    "cinsiyet = veriler.iloc[:,-1].values\n",
    "\n",
    "\n",
    "sonuc3 = pd.DataFrame(data = c[:,:1] , index=range(22), columns=['cinsiyet'])\n",
    "\n",
    "\n",
    "#dataframe birlestirme islemi\n",
    "s=pd.concat([sonuc,sonuc2],axis=1)\n",
    "\n",
    "\n",
    "s2= pd.concat([s,sonuc3],axis=1)\n",
    "\n",
    "#verilerin egitim ve test icin bolunmesi\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train,y_test = train_test_split(s,sonuc3,test_size=0.33, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130]\n",
      " [125]\n",
      " [135]\n",
      " [133]\n",
      " [129]\n",
      " [180]\n",
      " [190]\n",
      " [175]\n",
      " [177]\n",
      " [185]\n",
      " [165]\n",
      " [155]\n",
      " [160]\n",
      " [162]\n",
      " [167]\n",
      " [174]\n",
      " [193]\n",
      " [187]\n",
      " [183]\n",
      " [159]\n",
      " [164]\n",
      " [166]]\n",
      "     fr   tr   us  kilo  yas  cinsiyet\n",
      "0   0.0  1.0  0.0    30   10       1.0\n",
      "1   0.0  1.0  0.0    36   11       1.0\n",
      "2   0.0  1.0  0.0    34   10       0.0\n",
      "3   0.0  1.0  0.0    30    9       0.0\n",
      "4   0.0  1.0  0.0    38   12       1.0\n",
      "5   0.0  1.0  0.0    90   30       1.0\n",
      "6   0.0  1.0  0.0    80   25       1.0\n",
      "7   0.0  1.0  0.0    90   35       1.0\n",
      "8   0.0  1.0  0.0    60   22       0.0\n",
      "9   0.0  0.0  1.0   105   33       1.0\n",
      "10  0.0  0.0  1.0    55   27       0.0\n",
      "11  0.0  0.0  1.0    50   44       0.0\n",
      "12  0.0  0.0  1.0    58   39       0.0\n",
      "13  0.0  0.0  1.0    59   41       0.0\n",
      "14  0.0  0.0  1.0    62   55       0.0\n",
      "15  1.0  0.0  0.0    70   47       1.0\n",
      "16  1.0  0.0  0.0    90   23       1.0\n",
      "17  1.0  0.0  0.0    80   27       1.0\n",
      "18  1.0  0.0  0.0    88   28       1.0\n",
      "19  1.0  0.0  0.0    40   29       0.0\n",
      "20  1.0  0.0  0.0    66   32       0.0\n",
      "21  1.0  0.0  0.0    56   42       0.0\n",
      "[[182.26638686]\n",
      " [152.87161474]\n",
      " [162.79386375]\n",
      " [158.30668577]\n",
      " [130.82888952]\n",
      " [173.96138408]\n",
      " [150.12782663]\n",
      " [157.26898922]]\n",
      "[[164]\n",
      " [165]\n",
      " [167]\n",
      " [162]\n",
      " [125]\n",
      " [166]\n",
      " [155]\n",
      " [159]]\n"
     ]
    }
   ],
   "source": [
    "#1. kutuphaneler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#2. Veri Onisleme\n",
    "\n",
    "#2.1. Veri Yukleme\n",
    "veriler = pd.read_csv('veriler.csv')\n",
    "#pd.read_csv(\"veriler.csv\")\n",
    "\n",
    "\n",
    "#veri on isleme\n",
    "\n",
    "\n",
    "Yas = veriler.iloc[:,1:4].values\n",
    "\n",
    "\n",
    "#encoder:  Kategorik -> Numeric\n",
    "ulke = veriler.iloc[:,0:1].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "ulke[:,0] = le.fit_transform(ulke[:,0])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(categories=\"auto\")\n",
    "ulke=ohe.fit_transform(ulke).toarray()\n",
    "\n",
    "\n",
    "c = veriler.iloc[:,-1:].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "c[:,0] = le.fit_transform(c[:,0])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(categories=\"auto\")\n",
    "c=ohe.fit_transform(c).toarray()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#numpy dizileri dataframe donusumu\n",
    "sonuc = pd.DataFrame(data = ulke, index = range(22), columns=['fr','tr','us'] )\n",
    "\n",
    "\n",
    "sonuc2 =pd.DataFrame(data = Yas, index = range(22), columns = ['boy','kilo','yas'])\n",
    "\n",
    "\n",
    "cinsiyet = veriler.iloc[:,-1].values\n",
    "\n",
    "\n",
    "sonuc3 = pd.DataFrame(data = c[:,:1] , index=range(22), columns=['cinsiyet'])\n",
    "\n",
    "\n",
    "#dataframe birlestirme islemi\n",
    "s=pd.concat([sonuc,sonuc2],axis=1)\n",
    "\n",
    "\n",
    "s2= pd.concat([s,sonuc3],axis=1)\n",
    "\n",
    "#verilerin egitim ve test icin bolunmesi\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train,y_test = train_test_split(s,sonuc3,test_size=0.33, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "boy=s2.iloc[:,3:4].values\n",
    "print(boy)\n",
    "\n",
    "sol=s2.iloc[:,:3]\n",
    "sag=s2.iloc[:,4:]\n",
    "\n",
    "veri=pd.concat([sol,sag],axis=1)\n",
    "\n",
    "print(veri)\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(veri,boy,test_size=0.33, random_state=0)\n",
    "\n",
    "r2=LinearRegression()\n",
    "r2.fit(x_train,y_train)\n",
    "\n",
    "y_pred=r2.predict(x_test)\n",
    "\n",
    "print(y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python ile Geri Eleme(Backward Elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.885\n",
      "Model:                            OLS   Adj. R-squared:                  0.849\n",
      "Method:                 Least Squares   F-statistic:                     24.69\n",
      "Date:                Mon, 07 Sep 2020   Prob (F-statistic):           5.41e-07\n",
      "Time:                        17:51:50   Log-Likelihood:                -73.950\n",
      "No. Observations:                  22   AIC:                             159.9\n",
      "Df Residuals:                      16   BIC:                             166.4\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           114.0688      8.145     14.005      0.000      96.802     131.335\n",
      "x2           108.3030      5.736     18.880      0.000      96.143     120.463\n",
      "x3           104.4714      9.195     11.361      0.000      84.978     123.964\n",
      "x4             0.9211      0.119      7.737      0.000       0.669       1.174\n",
      "x5             0.0814      0.221      0.369      0.717      -0.386       0.549\n",
      "x6           -10.5980      5.052     -2.098      0.052     -21.308       0.112\n",
      "==============================================================================\n",
      "Omnibus:                        1.031   Durbin-Watson:                   2.759\n",
      "Prob(Omnibus):                  0.597   Jarque-Bera (JB):                0.624\n",
      "Skew:                           0.407   Prob(JB):                        0.732\n",
      "Kurtosis:                       2.863   Cond. No.                         524.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm \n",
    "#bir dizi oluşturup sırayla değişkenleri eleyeceğiz,hangisinin daha etkili oldugunu göreceğiz\n",
    "X = np.append(arr = np.ones((22,1)).astype(int), values=veri, axis=1 )#en başa birlerden oluşan dizi eklendi\n",
    "X_l = veri.iloc[:,[0,1,2,3,4,5]].values\n",
    "r_ols = sm.OLS(endog = boy, exog =X_l)#endog bağımlı değişken,exog bağımsız değişken\n",
    "r = r_ols.fit()\n",
    "print(r.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.884\n",
      "Model:                            OLS   Adj. R-squared:                  0.857\n",
      "Method:                 Least Squares   F-statistic:                     32.47\n",
      "Date:                Mon, 07 Sep 2020   Prob (F-statistic):           9.32e-08\n",
      "Time:                        17:51:54   Log-Likelihood:                -74.043\n",
      "No. Observations:                  22   AIC:                             158.1\n",
      "Df Residuals:                      17   BIC:                             163.5\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           115.6583      6.734     17.175      0.000     101.451     129.866\n",
      "x2           109.0786      5.200     20.978      0.000      98.108     120.049\n",
      "x3           106.5445      7.090     15.026      0.000      91.585     121.504\n",
      "x4             0.9405      0.104      9.029      0.000       0.721       1.160\n",
      "x5           -11.1093      4.733     -2.347      0.031     -21.096      -1.123\n",
      "==============================================================================\n",
      "Omnibus:                        0.871   Durbin-Watson:                   2.719\n",
      "Prob(Omnibus):                  0.647   Jarque-Bera (JB):                0.459\n",
      "Skew:                           0.351   Prob(JB):                        0.795\n",
      "Kurtosis:                       2.910   Cond. No.                         397.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm \n",
    "#bir dizi oluşturup sırayla değişkenleri eleyeceğiz,hangisinin daha etkili oldugunu göreceğiz\n",
    "X = np.append(arr = np.ones((22,1)).astype(int), values=veri, axis=1 )#en başa birlerden oluşan dizi eklendi\n",
    "X_l = veri.iloc[:,[0,1,2,3,5]].values\n",
    "r_ols = sm.OLS(endog = boy, exog =X_l)#endog bağımlı değişken,exog bağımsız değişken\n",
    "r = r_ols.fit()\n",
    "print(r.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "p değeri 0.05 altındaysa kabul edilebilir değerlerdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
